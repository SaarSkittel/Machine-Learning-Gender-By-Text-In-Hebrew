{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Competitive Assignment\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Saar Skittel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saar\\Computer Science\\Third year\\Second Semester\\Machine Learning\\Assignment3\\demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saar\\anaconda3\\lib\\site-packages\\hebrew_tokenizer\\tokenizer.py:121: FutureWarning: Possible nested set at position 729\n",
      "  self.scanner = re.compile(\n"
     ]
    }
   ],
   "source": [
    "# imports for reading and writing (input & output) files:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add whatever imports you need\n",
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = '.' + os.sep + 'input' + os.sep + 'annotated_corpus_for_train.xlsx'\n",
    "test_filename  = '.' + os.sep + 'input' + os.sep + 'corpus_for_test.xlsx'\n",
    "df_train = pd.read_excel(train_filename, 'corpus', index_col=None, na_values=['NA'])\n",
    "df_test  = pd.read_excel(test_filename,  'corpus', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>בוקר אחד קמתי סהרורי יצאתי מהמיטה קצת מטושטש ,...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>לחבר שלי היה יום הולדת וחיפשנו מה אפשר לעשות ל...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>השנה האחרונה הייתה שנת קורונה, שנה לא פשוטה בק...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>לפני כחצי שנה עברתי לגור בצפון עם בת זוגתי, עב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>יום חמישי רגיל, תמיד מתחיל לעבור טיפה מאוחר יו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>בשנה האחרונה חוויתי את מגפת הקורונה שהכריח את ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>בסמסטר קודם אני וכמה חברים ללימודים קבענו להיפ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>בשנה האחרונה למרות שלא היו יותר מידיי דברים לע...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story gender\n",
       "0  בוקר אחד קמתי סהרורי יצאתי מהמיטה קצת מטושטש ,...      m\n",
       "1  לחבר שלי היה יום הולדת וחיפשנו מה אפשר לעשות ל...      m\n",
       "2  השנה האחרונה הייתה שנת קורונה, שנה לא פשוטה בק...      m\n",
       "3  לפני כחצי שנה עברתי לגור בצפון עם בת זוגתי, עב...      m\n",
       "4  יום חמישי רגיל, תמיד מתחיל לעבור טיפה מאוחר יו...      m\n",
       "5  בשנה האחרונה חוויתי את מגפת הקורונה שהכריח את ...      m\n",
       "6  בסמסטר קודם אני וכמה חברים ללימודים קבענו להיפ...      m\n",
       "7  בשנה האחרונה למרות שלא היו יותר מידיי דברים לע...      f"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>כחלק ממסגרת ההתנדבות שלי במגלה אני הולך לפעמיי...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>לפני שנה החלטתי שאני רוצה להיות טייס, התחלתי ל...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>בתקופת הקורונה של תחילת החיסונים נגד קורונה, א...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_example_id                                              story\n",
       "0                0  כחלק ממסגרת ההתנדבות שלי במגלה אני הולך לפעמיי...\n",
       "1                1  לפני שנה החלטתי שאני רוצה להיות טייס, התחלתי ל...\n",
       "2                2  בתקופת הקורונה של תחילת החיסונים נגד קורונה, א..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stop words\n",
    "stop_words_filename = '.' + os.sep +'stop_word_list_heb_example.txt' #file location\n",
    "st = pd.read_csv(stop_words_filename, sep='\\n', header=None) #read file\n",
    "stop_words = st[0].tolist()#make a list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(hebrew_text):\n",
    "    token=ht.tokenize(hebrew_text)#tokenizing the text\n",
    "    return_tokens = list(filter(lambda x: (x[0]=='HEBREW' and len(x[1]) > 1), token)) #filtering to have only words in hebrew\n",
    "    return_tokens = [tuple[1] for tuple in return_tokens] #separating tuple resulted from tokenizer to only the words\n",
    "    return return_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = df_train.iloc[:int(len(df_train.index) *0.8)] #train set\n",
    "df_X_test = df_train.iloc[int(len(df_train.index) *0.8):,:] #validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(stop_words=['לא', 'את', 'זה', 'של', 'על', 'מה',\n",
       "                                             'עם', 'הוא', 'כל', 'אבל', 'גם',\n",
       "                                             'לי', 'יש', 'אם', 'אתה', 'רק',\n",
       "                                             'או', 'היה', 'אין', 'יותר', 'אז',\n",
       "                                             'היא', 'כי', 'לך', 'טוב', 'הם',\n",
       "                                             'מי', 'כמו', 'שלא', 'כבר', ...],\n",
       "                                 tokenizer=<function my_tokenizer at 0x000002613FFD94C0>)),\n",
       "                ('norm', Normalizer()),\n",
       "                ('clf',\n",
       "                 MLPClassifier(learning_rate_init=0.01, random_state=0,\n",
       "                               shuffle=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2_clf_mlp = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words= stop_words, tokenizer = my_tokenizer)), #using CountVectorizer with stop words and tokenizer\n",
    "    ('norm', preprocessing.Normalizer(norm= 'l2')), #l2 normalizer\n",
    "    ('clf',  MLPClassifier(max_iter=200,shuffle= False, learning_rate_init=0.01, random_state=0)), #using nueral networks classifier\n",
    "])\n",
    "text2_clf_mlp.fit(df_X_train.story, df_X_train.gender) #training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.55      0.60      0.57        20\n",
      "           m       0.84      0.81      0.83        53\n",
      "\n",
      "    accuracy                           0.75        73\n",
      "   macro avg       0.69      0.71      0.70        73\n",
      "weighted avg       0.76      0.75      0.76        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test run\n",
    "X2_test = df_X_test.story #validation set\n",
    "predicted2 = text2_clf_mlp.predict(X2_test) #predicting validation set\n",
    "print(metrics.classification_report(df_X_test.gender, predicted2)) #prediction classification evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(stop_words=['לא', 'את', 'זה', 'של', 'על', 'מה',\n",
       "                                             'עם', 'הוא', 'כל', 'אבל', 'גם',\n",
       "                                             'לי', 'יש', 'אם', 'אתה', 'רק',\n",
       "                                             'או', 'היה', 'אין', 'יותר', 'אז',\n",
       "                                             'היא', 'כי', 'לך', 'טוב', 'הם',\n",
       "                                             'מי', 'כמו', 'שלא', 'כבר', ...],\n",
       "                                 tokenizer=<function my_tokenizer at 0x000002613FFD94C0>)),\n",
       "                ('norm', Normalizer()),\n",
       "                ('clf',\n",
       "                 MLPClassifier(learning_rate_init=0.01, random_state=0,\n",
       "                               shuffle=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_mlp = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words = stop_words, tokenizer = my_tokenizer)), #using CountVectorizer with stop words and tokenizer\n",
    "    ('norm', preprocessing.Normalizer(norm='l2')), #l2 normalizer\n",
    "    ('clf', MLPClassifier(max_iter=200, shuffle= False, learning_rate_init=0.01, random_state=0)), #using nueral networks classifier\n",
    "])\n",
    "text_clf_mlp.fit(df_train.story, df_train.gender) #training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = df_test.story #test set\n",
    "predicted = text_clf_mlp.predict(X_test) #predicting test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     test_example_id predicted_category\n",
      "0                  0                  m\n",
      "1                  1                  m\n",
      "2                  2                  f\n",
      "3                  3                  m\n",
      "4                  4                  m\n",
      "..               ...                ...\n",
      "151              151                  m\n",
      "152              152                  f\n",
      "153              153                  m\n",
      "154              154                  m\n",
      "155              155                  f\n",
      "\n",
      "[156 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_predicted=pd.DataFrame(columns= ['test_example_id', 'predicted_category']) #creating dataframe to export prediction \n",
    "df_predicted['test_example_id']= df_test.test_example_id #writing index values to dataframe\n",
    "df_predicted['predicted_category'] = predicted #writing prediction to dataframe\n",
    "print(df_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False) #export results dataframe to csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
